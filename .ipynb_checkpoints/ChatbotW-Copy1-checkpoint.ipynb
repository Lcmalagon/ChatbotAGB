{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a26b4-6101-4c02-8418-98ffc08a9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain openai\n",
    "!pip install chromadb\n",
    "!pip install kaleido\n",
    "!pip install python-multipart\n",
    "!pip install tiktoken\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3a85e4-1c1a-48c3-b827-07cd5d9d5e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (0.0.337)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (0.0.65)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/lauramalagon/anaconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4126eb04-7f34-4072-ba03-cf8115ea3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1793fcf-c827-40c9-a0b8-978f6b47af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'what are all the columns', 'result': ' ID, First Name, Last Name, Current Title, Current Company, Previous Title, Previous Company, Location, Master Degree - College, Graduate Degree, Master Graduation Year, Bachelor Degree - College, Bachelor Degree, Bachelor Graduation Year, Associate Degree - College, Associate Degree, Associate Graduation Year, and High School.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Load the documents\n",
    "loader = CSVLoader(file_path='Clean Data .csv')\n",
    "# Create an index using the loaded documents\n",
    "index_creator = VectorstoreIndexCreator()\n",
    "docsearch = index_creator.from_loaders([loader])\n",
    "# Create a question-answering chain using the index\n",
    "chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
    "# Pass a query to the chain\n",
    "query = \"what are all the columns\"\n",
    "response = chain({\"question\": query})\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f815d0-9765-412e-8f7f-68d090ede044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "loader = CSVLoader(file_path='Clean Data  - Clean Data .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ab68f9-f688-4175-8f6d-9fc1d390841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index using the loaded documents\n",
    "index_creator = VectorstoreIndexCreator()\n",
    "docsearch = index_creator.from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10be2b2e-b3e8-4aa7-94cb-f9e9112fdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a question-answering chain using the index\n",
    "chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fda5a88-a738-4c90-875b-8bd121a60b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'what are all the columns', 'result': ' ID, First Name, Last Name, Current Title, Current Company, Previous Title, Previous Company, Location, Master Degree - College, Graduate Degree, Master Graduation Year, Bachelor Degree - College, Bachelor Degree, Bachelor Graduation Year, Associate Degree - College, Associate Degree, Associate Graduation Year, and High School.'}\n"
     ]
    }
   ],
   "source": [
    "# Pass a query to the chain\n",
    "query = \"what are all the columns\"\n",
    "response = chain({\"question\": query})\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80c52d5-871d-4018-abda-2cbf26df4b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'what alumni have a current position at department of defense position', 'result': ' Wesley Hill has a current position at the Deputy Assistant Secretary of the Navy RDT&E.'}\n"
     ]
    }
   ],
   "source": [
    "# Pass a query to the chain\n",
    "query = \"what alumni have a current position at department of defense position\"\n",
    "response = chain({\"question\": query})\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c0c4549-488b-4da6-aa5c-ffeb634ba294",
   "metadata": {},
   "source": [
    "what alumni have a current position at a religious institution\n",
    "what alumni have 2 masters degree\n",
    "what alumni went to Saint Mary's College of California for both bachelors and masters degree\n",
    "which alumni interned at Saint Mary's College of California\n",
    "which alumni have analyst positions \n",
    "can you tell me the name of alumnae that have 'analyst' in current position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e3d87-65bd-4ed1-b959-a6a67c05c3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28161e4b-caad-4032-99bc-6a2c5bab6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the CSV data\n",
    "# data = pd.read_csv('alumni_data - alumni_data.csv')\n",
    "\n",
    "# # Define the columns you want to use for Q&A\n",
    "# columns = ['currentJob', 'job', 'location', 'name', 'additionalInfo', 'summary', 'pastJob']\n",
    "\n",
    "# # Create Q&A pairs for each column\n",
    "# qa_data = []\n",
    "# for column in columns:\n",
    "#     for value in data[column].dropna().unique():\n",
    "#         qa_data.append({'question': f\"What is the {column} of {value}?\", 'answer': data[data[column] == value][column].values[0]})\n",
    "\n",
    "# # Split your data into training, validation, and test sets as mentioned in the previous response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "699a48af-3e3b-443a-a305-133102888468",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define your fine-tuning parameters\u001b[39;00m\n\u001b[1;32m      4\u001b[0m fine_tuning_parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_set\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mval_data\u001b[49m,  \u001b[38;5;66;03m# Use your validation dataset here\u001b[39;00m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mfine_tuning_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m     messages\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     log_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "\n",
    "# # Define your fine-tuning parameters\n",
    "# fine_tuning_parameters = {\n",
    "#     \"model\": \"gpt-3.5-turbo\",\n",
    "#     \"n\": 1,\n",
    "#     \"stop\": None,\n",
    "#     \"temperature\": 0.7,\n",
    "#     \"max_tokens\": 100,\n",
    "#     \"validation_set\": val_data,  # Use your validation dataset here\n",
    "# }\n",
    "\n",
    "# # Fine-tune the model\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     model=fine_tuning_parameters[\"model\"],\n",
    "#     messages=train_data,\n",
    "#     max_tokens=fine_tuning_parameters[\"max_tokens\"],\n",
    "#     n=fine_tuning_parameters[\"n\"],\n",
    "#     stop=fine_tuning_parameters[\"stop\"],\n",
    "#     temperature=fine_tuning_parameters[\"temperature\"],\n",
    "#     validation_set=fine_tuning_parameters[\"validation_set\"],\n",
    "#     log_level=\"info\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd9786-d956-4d71-892a-d63f6d70b8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
